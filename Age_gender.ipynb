{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d23af5-82cf-448c-86f3-013f1f82a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bf7af13-b69d-4d78-845e-57726fc5b5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    # Set TensorFlow to use only the GPU devices\n",
    "    tf.config.experimental.set_visible_devices(gpus, 'GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)  \n",
    "print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48645e04-cc03-4cb7-8ce3-954150116d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"F:\\ML Python VsCode\\Age_Gender_Emotion_Prediction_using_CNN\\UTKFace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f575c90f-1b26-44f6-9bc9-f88a22a4584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = []\n",
    "gender = []\n",
    "image = []\n",
    "for file in os.listdir(folder_path):\n",
    "    age.append(int(file.split('_')[0]))\n",
    "    gender.append(int(file.split('_')[1]))\n",
    "    image.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55429de-dc15-42b7-8e8c-7d65bdcb6aaa",
   "metadata": {},
   "source": [
    "<style>\n",
    ".output_area pre {\n",
    "    color: white; /* Change output text color to white */\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "760ebc49-e306-49ac-95f5-09f7e0acc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'age':age,'gender':gender,'image':image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0046390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11721</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32_0_1_20170113141930308.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11922</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>32_1_0_20170103181859185.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21516</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>68_0_0_20170104213011828.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1_2_20161219211512447.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  gender                                  image\n",
       "11721   32       0  32_0_1_20170113141930308.jpg.chip.jpg\n",
       "11922   32       1  32_1_0_20170103181859185.jpg.chip.jpg\n",
       "21516   68       0  68_0_0_20170104213011828.jpg.chip.jpg\n",
       "2480     1       1   1_1_2_20161219211512447.jpg.chip.jpg"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e223a142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23708, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a67ddc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.sample(frac=1,random_state=0).iloc[:20000]\n",
    "test_df = df.sample(frac=1,random_state=0).iloc[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68f27de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ae598ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3708, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fc47af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range = 0.1,\n",
    "    zoom_range = 0.05,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32c6b8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames.\n",
      "Found 3708 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(train_df,directory=folder_path,x_col='image',y_col=['age','gender'],target_size=(200,200),class_mode='multi_output')\n",
    "test_generator = test_datagen.flow_from_dataframe(test_df,directory=folder_path,x_col='image',y_col=['age','gender'],target_size=(200,200),class_mode='multi_output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fe4403",
   "metadata": {},
   "source": [
    "## Model Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40d1c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.layers import *\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "715cda9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vggnet = VGG16(include_top = False,input_shape=(200,200,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b92d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vggnet.trainable = False\n",
    "output = vggnet.layers[-1].output\n",
    "flatten = Flatten()(output)\n",
    "\n",
    "dense1 = Dense(512,activation='elu')(flatten)\n",
    "dense2 = Dense(512,activation='elu')(flatten)\n",
    "\n",
    "dense3 = Dense(512,activation='elu')(dense1)\n",
    "dense4 = Dense(512,activation='elu')(dense2)\n",
    "\n",
    "output1 = Dense(1,activation='linear',name='age')(dense3)\n",
    "output2 = Dense(1,activation='sigmoid',name='gender')(dense4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94f9cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=vggnet.input,outputs=[output1,output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "278f44fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 200, 200, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 200, 200, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 200, 200, 64  36928       ['block1_conv1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 100, 100, 64  0           ['block1_conv2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 100, 100, 12  73856       ['block1_pool[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 100, 100, 12  147584      ['block2_conv1[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 50, 50, 128)  0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 50, 50, 256)  295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 50, 50, 256)  590080      ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 50, 50, 256)  590080      ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 25, 25, 256)  0           ['block3_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 25, 25, 512)  1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 25, 25, 512)  2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 25, 25, 512)  2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 12, 12, 512)  0           ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 12, 12, 512)  2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 12, 12, 512)  2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 12, 12, 512)  2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_pool (MaxPooling2D)     (None, 6, 6, 512)    0           ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 18432)        0           ['block5_pool[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          9437696     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          9437696     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 512)          262656      ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 512)          262656      ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " age (Dense)                    (None, 1)            513         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " gender (Dense)                 (None, 1)            513         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34,116,418\n",
      "Trainable params: 19,401,730\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7bfcd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss={'age':'mae','gender':'binary_crossentropy'},metrics={'age':'mae','gender':'accuracy'},loss_weights={'age':20,'gender':80})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e7bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 621s 993ms/step - loss: 235.1607 - age_loss: 9.8062 - gender_loss: 0.4880 - age_mae: 9.8062 - gender_accuracy: 0.7630 - val_loss: 192.5024 - val_age_loss: 8.2396 - val_gender_loss: 0.3464 - val_age_mae: 8.2396 - val_gender_accuracy: 0.8484\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 181s 290ms/step - loss: 207.9047 - age_loss: 8.7391 - gender_loss: 0.4140 - age_mae: 8.7391 - gender_accuracy: 0.8058 - val_loss: 189.5595 - val_age_loss: 8.0457 - val_gender_loss: 0.3581 - val_age_mae: 8.0457 - val_gender_accuracy: 0.8484\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 184s 294ms/step - loss: 203.4116 - age_loss: 8.5491 - gender_loss: 0.4054 - age_mae: 8.5491 - gender_accuracy: 0.8083 - val_loss: 180.3287 - val_age_loss: 7.6933 - val_gender_loss: 0.3308 - val_age_mae: 7.6933 - val_gender_accuracy: 0.8568\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 183s 293ms/step - loss: 200.6972 - age_loss: 8.4767 - gender_loss: 0.3895 - age_mae: 8.4767 - gender_accuracy: 0.8217 - val_loss: 181.4518 - val_age_loss: 7.7364 - val_gender_loss: 0.3340 - val_age_mae: 7.7364 - val_gender_accuracy: 0.8549\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 184s 293ms/step - loss: 193.6425 - age_loss: 8.1619 - gender_loss: 0.3801 - age_mae: 8.1619 - gender_accuracy: 0.8259 - val_loss: 176.8900 - val_age_loss: 7.5612 - val_gender_loss: 0.3208 - val_age_mae: 7.5612 - val_gender_accuracy: 0.8571\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 184s 294ms/step - loss: 191.4292 - age_loss: 8.0489 - gender_loss: 0.3806 - age_mae: 8.0489 - gender_accuracy: 0.8228 - val_loss: 184.2345 - val_age_loss: 7.7943 - val_gender_loss: 0.3544 - val_age_mae: 7.7943 - val_gender_accuracy: 0.8425\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 185s 296ms/step - loss: 189.9836 - age_loss: 7.9893 - gender_loss: 0.3775 - age_mae: 7.9893 - gender_accuracy: 0.8258 - val_loss: 172.2381 - val_age_loss: 7.3566 - val_gender_loss: 0.3138 - val_age_mae: 7.3566 - val_gender_accuracy: 0.8633\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 185s 295ms/step - loss: 188.1872 - age_loss: 7.9868 - gender_loss: 0.3556 - age_mae: 7.9868 - gender_accuracy: 0.8379 - val_loss: 175.4367 - val_age_loss: 7.4359 - val_gender_loss: 0.3340 - val_age_mae: 7.4359 - val_gender_accuracy: 0.8549\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 184s 295ms/step - loss: 185.6069 - age_loss: 7.8339 - gender_loss: 0.3616 - age_mae: 7.8339 - gender_accuracy: 0.8347 - val_loss: 176.3779 - val_age_loss: 7.6433 - val_gender_loss: 0.2939 - val_age_mae: 7.6433 - val_gender_accuracy: 0.8751\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 184s 293ms/step - loss: 185.1767 - age_loss: 7.8063 - gender_loss: 0.3631 - age_mae: 7.8063 - gender_accuracy: 0.8321 - val_loss: 169.1919 - val_age_loss: 7.2219 - val_gender_loss: 0.3094 - val_age_mae: 7.2219 - val_gender_accuracy: 0.8649\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 184s 294ms/step - loss: 182.0873 - age_loss: 7.7046 - gender_loss: 0.3499 - age_mae: 7.7046 - gender_accuracy: 0.8386 - val_loss: 172.2819 - val_age_loss: 7.4383 - val_gender_loss: 0.2940 - val_age_mae: 7.4383 - val_gender_accuracy: 0.8606\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 184s 294ms/step - loss: 180.6681 - age_loss: 7.6284 - gender_loss: 0.3512 - age_mae: 7.6284 - gender_accuracy: 0.8359 - val_loss: 164.9200 - val_age_loss: 7.0748 - val_gender_loss: 0.2928 - val_age_mae: 7.0748 - val_gender_accuracy: 0.8692\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 185s 295ms/step - loss: 179.9436 - age_loss: 7.5907 - gender_loss: 0.3516 - age_mae: 7.5907 - gender_accuracy: 0.8379 - val_loss: 165.4198 - val_age_loss: 7.1228 - val_gender_loss: 0.2870 - val_age_mae: 7.1228 - val_gender_accuracy: 0.8706\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 184s 294ms/step - loss: 178.1114 - age_loss: 7.5434 - gender_loss: 0.3405 - age_mae: 7.5434 - gender_accuracy: 0.8436 - val_loss: 171.3262 - val_age_loss: 7.1560 - val_gender_loss: 0.3526 - val_age_mae: 7.1560 - val_gender_accuracy: 0.8498\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 184s 294ms/step - loss: 177.8508 - age_loss: 7.5102 - gender_loss: 0.3456 - age_mae: 7.5102 - gender_accuracy: 0.8400 - val_loss: 166.0028 - val_age_loss: 7.0048 - val_gender_loss: 0.3238 - val_age_mae: 7.0048 - val_gender_accuracy: 0.8506\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 183s 292ms/step - loss: 176.4031 - age_loss: 7.4616 - gender_loss: 0.3396 - age_mae: 7.4616 - gender_accuracy: 0.8445 - val_loss: 164.5524 - val_age_loss: 7.0818 - val_gender_loss: 0.2864 - val_age_mae: 7.0818 - val_gender_accuracy: 0.8703\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 184s 294ms/step - loss: 175.0931 - age_loss: 7.4110 - gender_loss: 0.3359 - age_mae: 7.4110 - gender_accuracy: 0.8473 - val_loss: 165.0356 - val_age_loss: 7.0982 - val_gender_loss: 0.2884 - val_age_mae: 7.0982 - val_gender_accuracy: 0.8778\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 184s 294ms/step - loss: 175.9870 - age_loss: 7.4800 - gender_loss: 0.3298 - age_mae: 7.4800 - gender_accuracy: 0.8521 - val_loss: 169.5924 - val_age_loss: 7.1517 - val_gender_loss: 0.3320 - val_age_mae: 7.1517 - val_gender_accuracy: 0.8581\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 184s 295ms/step - loss: 173.3805 - age_loss: 7.3525 - gender_loss: 0.3291 - age_mae: 7.3525 - gender_accuracy: 0.8517 - val_loss: 163.7179 - val_age_loss: 7.0395 - val_gender_loss: 0.2866 - val_age_mae: 7.0395 - val_gender_accuracy: 0.8743\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - ETA: 0s - loss: 172.4171 - age_loss: 7.3030 - gender_loss: 0.3295 - age_mae: 7.3030 - gender_accuracy: 0.8491"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator,epochs=20,validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6426a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1374edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
